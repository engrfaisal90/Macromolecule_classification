{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/faisalg/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/faisalg/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/faisalg/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/faisalg/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/faisalg/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/faisalg/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from preprocess import load_data, next_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structureId</th>\n",
       "      <th>chainId</th>\n",
       "      <th>sequence</th>\n",
       "      <th>residueCount</th>\n",
       "      <th>macromoleculeType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100D</td>\n",
       "      <td>A</td>\n",
       "      <td>CCGGCGCCGG</td>\n",
       "      <td>20</td>\n",
       "      <td>DNA/RNA Hybrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100D</td>\n",
       "      <td>B</td>\n",
       "      <td>CCGGCGCCGG</td>\n",
       "      <td>20</td>\n",
       "      <td>DNA/RNA Hybrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101D</td>\n",
       "      <td>A</td>\n",
       "      <td>CGCGAATTCGCG</td>\n",
       "      <td>24</td>\n",
       "      <td>DNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101D</td>\n",
       "      <td>B</td>\n",
       "      <td>CGCGAATTCGCG</td>\n",
       "      <td>24</td>\n",
       "      <td>DNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101M</td>\n",
       "      <td>A</td>\n",
       "      <td>MVLSEGEWQLVLHVWAKVEADVAGHGQDILIRLFKSHPETLEKFDR...</td>\n",
       "      <td>154</td>\n",
       "      <td>Protein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  structureId chainId                                           sequence  \\\n",
       "0        100D       A                                         CCGGCGCCGG   \n",
       "1        100D       B                                         CCGGCGCCGG   \n",
       "2        101D       A                                       CGCGAATTCGCG   \n",
       "3        101D       B                                       CGCGAATTCGCG   \n",
       "4        101M       A  MVLSEGEWQLVLHVWAKVEADVAGHGQDILIRLFKSHPETLEKFDR...   \n",
       "\n",
       "   residueCount macromoleculeType  \n",
       "0            20    DNA/RNA Hybrid  \n",
       "1            20    DNA/RNA Hybrid  \n",
       "2            24               DNA  \n",
       "3            24               DNA  \n",
       "4           154           Protein  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = pd.read_csv('pdb_data_seq.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'macromoleculeType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-db6325aacb52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmacromoleculeType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Macro Mol Type'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5055\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5056\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5057\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5059\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'macromoleculeType'"
     ]
    }
   ],
   "source": [
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "ex = data.macromoleculeType.value_counts()\n",
    "print(ex)\n",
    "a = 'Macro Mol Type'\n",
    "colors = ['SlateGray','Orange','Green','DodgerBlue','DodgerBlue','DodgerBlue','DodgerBlue','DodgerBlue','DodgerBlue',\n",
    "        'DodgerBlue','DodgerBlue','DodgerBlue','DodgerBlue']\n",
    "fig = {\n",
    "      \"data\": [\n",
    "        {\n",
    "          \"values\":ex.values,\n",
    "          \"labels\":ex.index,\n",
    "          \"text\":a,\n",
    "          \"textposition\":\"inside\",\n",
    "          #\"domain\": {\"x\": [0, .33]},\n",
    "          \"textfont\": {'size':12,'color':'white'},  \n",
    "          \"name\": a,\n",
    "          \"hoverinfo\":\"label+percent+name\",\n",
    "          \"hole\": .4,\n",
    "          'marker':{'colors':colors\n",
    "                   },\n",
    "          \"type\": \"pie\"\n",
    "        }],\n",
    "    \"layout\": {\n",
    "            \"title\":\"Macro Molecule type Distribution\",\n",
    "            \"annotations\": [\n",
    "                {\n",
    "                    \"font\": {\n",
    "                        \"size\": 20\n",
    "                    },\n",
    "                    \"showarrow\": False,\n",
    "                    \"text\": a,\n",
    "                    \"x\": 0.50,\n",
    "                    \"y\": 0.5\n",
    "                }]\n",
    "            }\n",
    "        }\n",
    "iplot(fig)                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(432474, 5)\n"
     ]
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "#print(data.isnull().sum())\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as py\n",
    "print ('There are more than 10 macro molecules used in this dataset but PROTEIN is widely used than the others')\n",
    "\n",
    "ex = data.macromoleculeType.value_counts()\n",
    "print(ex)\n",
    "a = 'Macro Mol Type'\n",
    "colors = ['SlateGray','Orange','Green','DodgerBlue','DodgerBlue','DodgerBlue','DodgerBlue','DodgerBlue','DodgerBlue',\n",
    "        'DodgerBlue','DodgerBlue','DodgerBlue','DodgerBlue']\n",
    "fig = {\n",
    "      \"data\": [\n",
    "        {\n",
    "          \"values\":ex.values,\n",
    "          \"labels\":ex.index,\n",
    "          \"text\":a,\n",
    "          \"textposition\":\"inside\",\n",
    "          #\"domain\": {\"x\": [0, .33]},\n",
    "          \"textfont\": {'size':12,'color':'white'},  \n",
    "          \"name\": a,\n",
    "          \"hoverinfo\":\"label+percent+name\",\n",
    "          \"hole\": .4,\n",
    "          'marker':{'colors':colors\n",
    "                   },\n",
    "          \"type\": \"pie\"\n",
    "        }],\n",
    "    \"layout\": {\n",
    "            \"title\":\"Macro Molecule type Distribution\",\n",
    "            \"annotations\": [\n",
    "                {\n",
    "                    \"font\": {\n",
    "                        \"size\": 20\n",
    "                    },\n",
    "                    \"showarrow\": False,\n",
    "                    \"text\": a,\n",
    "                    \"x\": 0.50,\n",
    "                    \"y\": 0.5\n",
    "                }]\n",
    "            }\n",
    "        }\n",
    "py.plot(fig)                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(432474, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = []\n",
    "for i in range(len(data)):\n",
    "    if data[i][4] == '':\n",
    "        continue\n",
    "    elif data[i][4] == 'DNA' or data[i][4]== 'Protein'or data[i][4] == 'RNA':\n",
    "        new_data.append([data[i][2],data[i][4]])\n",
    "    else:\n",
    "        new_data.append([data[i][2],'Hybrid'])\n",
    "        \n",
    "new_data = np.array(new_data)\n",
    "new_data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCGGCGCCGG</td>\n",
       "      <td>Hybrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCGGCGCCGG</td>\n",
       "      <td>Hybrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CGCGAATTCGCG</td>\n",
       "      <td>DNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CGCGAATTCGCG</td>\n",
       "      <td>DNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MVLSEGEWQLVLHVWAKVEADVAGHGQDILIRLFKSHPETLEKFDR...</td>\n",
       "      <td>Protein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence     type\n",
       "0                                         CCGGCGCCGG   Hybrid\n",
       "1                                         CCGGCGCCGG   Hybrid\n",
       "2                                       CGCGAATTCGCG      DNA\n",
       "3                                       CGCGAATTCGCG      DNA\n",
       "4  MVLSEGEWQLVLHVWAKVEADVAGHGQDILIRLFKSHPETLEKFDR...  Protein"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(new_data, columns=['sequence', 'type'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import text, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# maximum length of sequence, everything afterwards is discarded!\n",
    "max_length = 512\n",
    "seqs = data.sequence.values\n",
    "#create and fit tokenizer\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(seqs)\n",
    "#represent input data as word rank number sequences\n",
    "X = tokenizer.texts_to_sequences(seqs)\n",
    "X = sequence.pad_sequences(X, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Transform labels to one-hot\n",
    "lb = LabelBinarizer()\n",
    "Y = lb.fit_transform(data.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_30 (Embedding)     (None, 512, 8)            208       \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 512, 32)           800       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 256, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 256, 32)           3104      \n",
      "_________________________________________________________________\n",
      "lstm_52 (LSTM)               (None, 256, 100)          53200     \n",
      "_________________________________________________________________\n",
      "lstm_53 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 138,116\n",
      "Trainable params: 138,116\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 345979 samples, validate on 86495 samples\n",
      "Epoch 1/10\n",
      "345979/345979 [==============================] - 2257s 7ms/step - loss: 0.1310 - acc: 0.9546 - val_loss: 0.0997 - val_acc: 0.9647\n",
      "Epoch 2/10\n",
      "345979/345979 [==============================] - 3090s 9ms/step - loss: 0.0969 - acc: 0.9668 - val_loss: 0.0922 - val_acc: 0.9670\n",
      "Epoch 3/10\n",
      "345979/345979 [==============================] - 2197s 6ms/step - loss: 0.0817 - acc: 0.9722 - val_loss: 0.0752 - val_acc: 0.9748\n",
      "Epoch 4/10\n",
      "345979/345979 [==============================] - 2439s 7ms/step - loss: 0.0709 - acc: 0.9758 - val_loss: 0.0695 - val_acc: 0.9762\n",
      "Epoch 5/10\n",
      "345979/345979 [==============================] - 2357s 7ms/step - loss: 0.0632 - acc: 0.9783 - val_loss: 0.0695 - val_acc: 0.9770\n",
      "Epoch 6/10\n",
      "345979/345979 [==============================] - 2206s 6ms/step - loss: 0.0570 - acc: 0.9803 - val_loss: 0.0586 - val_acc: 0.9800\n",
      "Epoch 7/10\n",
      "345979/345979 [==============================] - 2744s 8ms/step - loss: 0.0529 - acc: 0.9817 - val_loss: 0.0549 - val_acc: 0.9809\n",
      "Epoch 8/10\n",
      "345979/345979 [==============================] - 2667s 8ms/step - loss: 0.0488 - acc: 0.9829 - val_loss: 0.0514 - val_acc: 0.9822\n",
      "Epoch 9/10\n",
      "345979/345979 [==============================] - 2348s 7ms/step - loss: 0.0454 - acc: 0.9839 - val_loss: 0.0468 - val_acc: 0.9833\n",
      "Epoch 10/10\n",
      "345979/345979 [==============================] - 2347s 7ms/step - loss: 0.0431 - acc: 0.9846 - val_loss: 0.0463 - val_acc: 0.9838\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(tokenizer.word_index)+1, embedding_dim, input_length=max_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(LSTM(100,return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(4, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2)\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import itertools\n",
    "\n",
    "train_pred = model.predict(X_train)\n",
    "test_pred = model.predict(X_test)\n",
    "print(\"train-acc = \" + str(accuracy_score(np.argmax(y_train, axis=1), np.argmax(train_pred, axis=1))*100))\n",
    "print(\"test-acc = \" + str(accuracy_score(np.argmax(y_test, axis=1), np.argmax(test_pred, axis=1))*100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 20, 8)             184       \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 20, 64)            3136      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 10, 32)            6176      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               20608     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 30,620\n",
      "Trainable params: 30,620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 2367 samples, validate on 1014 samples\n",
      "Epoch 1/50\n",
      "2367/2367 [==============================] - 6s 3ms/step - loss: 0.9506 - acc: 0.9104 - val_loss: 0.4088 - val_acc: 0.9063\n",
      "Epoch 2/50\n",
      "2367/2367 [==============================] - 0s 96us/step - loss: 0.4071 - acc: 0.9134 - val_loss: 0.3537 - val_acc: 0.9063\n",
      "Epoch 3/50\n",
      "2367/2367 [==============================] - 0s 154us/step - loss: 0.3183 - acc: 0.9134 - val_loss: 0.3060 - val_acc: 0.9063\n",
      "Epoch 4/50\n",
      "2367/2367 [==============================] - 0s 125us/step - loss: 0.2714 - acc: 0.9134 - val_loss: 0.2579 - val_acc: 0.9063\n",
      "Epoch 5/50\n",
      "2367/2367 [==============================] - 0s 106us/step - loss: 0.2341 - acc: 0.9134 - val_loss: 0.2304 - val_acc: 0.9063\n",
      "Epoch 6/50\n",
      "2367/2367 [==============================] - 0s 91us/step - loss: 0.2129 - acc: 0.9362 - val_loss: 0.2133 - val_acc: 0.9398\n",
      "Epoch 7/50\n",
      "2367/2367 [==============================] - 0s 115us/step - loss: 0.1976 - acc: 0.9392 - val_loss: 0.2006 - val_acc: 0.9408\n",
      "Epoch 8/50\n",
      "2367/2367 [==============================] - 0s 133us/step - loss: 0.1873 - acc: 0.9396 - val_loss: 0.1911 - val_acc: 0.9408\n",
      "Epoch 9/50\n",
      "2367/2367 [==============================] - 0s 101us/step - loss: 0.1788 - acc: 0.9404 - val_loss: 0.1854 - val_acc: 0.9408\n",
      "Epoch 10/50\n",
      "2367/2367 [==============================] - 0s 85us/step - loss: 0.1728 - acc: 0.9417 - val_loss: 0.1813 - val_acc: 0.9408\n",
      "Epoch 11/50\n",
      "2367/2367 [==============================] - 0s 85us/step - loss: 0.1678 - acc: 0.9417 - val_loss: 0.1798 - val_acc: 0.9408\n",
      "Epoch 12/50\n",
      "2367/2367 [==============================] - 0s 92us/step - loss: 0.1591 - acc: 0.9425 - val_loss: 0.1741 - val_acc: 0.9389\n",
      "Epoch 13/50\n",
      "2367/2367 [==============================] - 0s 101us/step - loss: 0.1542 - acc: 0.9430 - val_loss: 0.1683 - val_acc: 0.9379\n",
      "Epoch 14/50\n",
      "2367/2367 [==============================] - 0s 93us/step - loss: 0.1514 - acc: 0.9451 - val_loss: 0.1641 - val_acc: 0.9398\n",
      "Epoch 15/50\n",
      "2367/2367 [==============================] - 0s 87us/step - loss: 0.1448 - acc: 0.9459 - val_loss: 0.1646 - val_acc: 0.9418\n",
      "Epoch 16/50\n",
      "2367/2367 [==============================] - 0s 85us/step - loss: 0.1337 - acc: 0.9472 - val_loss: 0.1594 - val_acc: 0.9458\n",
      "Epoch 17/50\n",
      "2367/2367 [==============================] - 0s 83us/step - loss: 0.1232 - acc: 0.9535 - val_loss: 0.1594 - val_acc: 0.9458\n",
      "Epoch 18/50\n",
      "2367/2367 [==============================] - 0s 83us/step - loss: 0.1170 - acc: 0.9523 - val_loss: 0.1566 - val_acc: 0.9467\n",
      "Epoch 19/50\n",
      "2367/2367 [==============================] - 0s 88us/step - loss: 0.1148 - acc: 0.9518 - val_loss: 0.1521 - val_acc: 0.9418\n",
      "Epoch 20/50\n",
      "2367/2367 [==============================] - 0s 87us/step - loss: 0.1040 - acc: 0.9535 - val_loss: 0.1529 - val_acc: 0.9438\n",
      "Epoch 21/50\n",
      "2367/2367 [==============================] - 0s 82us/step - loss: 0.0992 - acc: 0.9506 - val_loss: 0.1540 - val_acc: 0.9428\n",
      "Epoch 22/50\n",
      "2367/2367 [==============================] - 0s 79us/step - loss: 0.0935 - acc: 0.9569 - val_loss: 0.1476 - val_acc: 0.9497\n",
      "Epoch 23/50\n",
      "2367/2367 [==============================] - 0s 83us/step - loss: 0.0877 - acc: 0.9611 - val_loss: 0.1459 - val_acc: 0.9438\n",
      "Epoch 24/50\n",
      "2367/2367 [==============================] - 0s 90us/step - loss: 0.0827 - acc: 0.9594 - val_loss: 0.1507 - val_acc: 0.9527\n",
      "Epoch 25/50\n",
      "2367/2367 [==============================] - 0s 88us/step - loss: 0.0767 - acc: 0.9654 - val_loss: 0.1462 - val_acc: 0.9477\n",
      "Epoch 26/50\n",
      "2367/2367 [==============================] - 0s 89us/step - loss: 0.0725 - acc: 0.9696 - val_loss: 0.1460 - val_acc: 0.9497\n",
      "Epoch 27/50\n",
      "2367/2367 [==============================] - 0s 89us/step - loss: 0.0666 - acc: 0.9658 - val_loss: 0.1449 - val_acc: 0.9527\n",
      "Epoch 28/50\n",
      "2367/2367 [==============================] - 0s 91us/step - loss: 0.0633 - acc: 0.9755 - val_loss: 0.1458 - val_acc: 0.9497\n",
      "Epoch 29/50\n",
      "2367/2367 [==============================] - 0s 97us/step - loss: 0.0594 - acc: 0.9759 - val_loss: 0.1450 - val_acc: 0.9517\n",
      "Epoch 30/50\n",
      "2367/2367 [==============================] - 0s 91us/step - loss: 0.0535 - acc: 0.9776 - val_loss: 0.1543 - val_acc: 0.9536\n",
      "Epoch 31/50\n",
      "2367/2367 [==============================] - 0s 101us/step - loss: 0.0586 - acc: 0.9730 - val_loss: 0.1551 - val_acc: 0.9477\n",
      "Epoch 32/50\n",
      "2367/2367 [==============================] - 0s 102us/step - loss: 0.0569 - acc: 0.9763 - val_loss: 0.1553 - val_acc: 0.9566\n",
      "Epoch 33/50\n",
      "2367/2367 [==============================] - 0s 85us/step - loss: 0.0489 - acc: 0.9789 - val_loss: 0.1583 - val_acc: 0.9556\n",
      "Epoch 34/50\n",
      "2367/2367 [==============================] - 0s 95us/step - loss: 0.0484 - acc: 0.9814 - val_loss: 0.1612 - val_acc: 0.9497\n",
      "Epoch 35/50\n",
      "2367/2367 [==============================] - 0s 105us/step - loss: 0.0465 - acc: 0.9797 - val_loss: 0.1618 - val_acc: 0.9536\n",
      "Epoch 36/50\n",
      "2367/2367 [==============================] - 0s 95us/step - loss: 0.0475 - acc: 0.9785 - val_loss: 0.1745 - val_acc: 0.9536\n",
      "Epoch 37/50\n",
      "2367/2367 [==============================] - 0s 89us/step - loss: 0.0472 - acc: 0.9823 - val_loss: 0.1679 - val_acc: 0.9507\n",
      "Epoch 38/50\n",
      "2367/2367 [==============================] - 0s 95us/step - loss: 0.0488 - acc: 0.9793 - val_loss: 0.1582 - val_acc: 0.9546\n",
      "Epoch 39/50\n",
      "2367/2367 [==============================] - 0s 94us/step - loss: 0.0438 - acc: 0.9839 - val_loss: 0.1655 - val_acc: 0.9566\n",
      "Epoch 40/50\n",
      "2367/2367 [==============================] - 0s 96us/step - loss: 0.0429 - acc: 0.9856 - val_loss: 0.1698 - val_acc: 0.9536\n",
      "Epoch 41/50\n",
      "2367/2367 [==============================] - 0s 91us/step - loss: 0.0394 - acc: 0.9839 - val_loss: 0.1779 - val_acc: 0.9546\n",
      "Epoch 42/50\n",
      "2367/2367 [==============================] - 0s 109us/step - loss: 0.0411 - acc: 0.9831 - val_loss: 0.1823 - val_acc: 0.9546\n",
      "Epoch 43/50\n",
      "2367/2367 [==============================] - 0s 93us/step - loss: 0.0395 - acc: 0.9852 - val_loss: 0.1710 - val_acc: 0.9586\n",
      "Epoch 44/50\n",
      "2367/2367 [==============================] - 0s 84us/step - loss: 0.0392 - acc: 0.9856 - val_loss: 0.1712 - val_acc: 0.9576\n",
      "Epoch 45/50\n",
      "2367/2367 [==============================] - 0s 83us/step - loss: 0.0365 - acc: 0.9856 - val_loss: 0.1664 - val_acc: 0.9625\n",
      "Epoch 46/50\n",
      "2367/2367 [==============================] - 0s 98us/step - loss: 0.0367 - acc: 0.9865 - val_loss: 0.1756 - val_acc: 0.9615\n",
      "Epoch 47/50\n",
      "2367/2367 [==============================] - 0s 90us/step - loss: 0.0389 - acc: 0.9852 - val_loss: 0.1725 - val_acc: 0.9606\n",
      "Epoch 48/50\n",
      "2367/2367 [==============================] - 0s 76us/step - loss: 0.0343 - acc: 0.9877 - val_loss: 0.1705 - val_acc: 0.9586\n",
      "Epoch 49/50\n",
      "2367/2367 [==============================] - 0s 113us/step - loss: 0.0338 - acc: 0.9877 - val_loss: 0.1757 - val_acc: 0.9625\n",
      "Epoch 50/50\n",
      "2367/2367 [==============================] - 0s 124us/step - loss: 0.0333 - acc: 0.9869 - val_loss: 0.1696 - val_acc: 0.9566\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "embedding_dim = 8\n",
    "\n",
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(tokenizer.word_index)+1, embedding_dim, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(Conv1D(filters=64, kernel_size=6, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=50, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, 20, 8)             184       \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 20, 400)           334400    \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 400)               961600    \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 100)               40100     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 1,336,688\n",
      "Trainable params: 1,336,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 2367 samples, validate on 1014 samples\n",
      "Epoch 1/10\n",
      "2367/2367 [==============================] - 23s 10ms/step - loss: 0.5354 - acc: 0.7500 - val_loss: 0.4119 - val_acc: 0.7500\n",
      "Epoch 2/10\n",
      "2367/2367 [==============================] - 14s 6ms/step - loss: 0.2927 - acc: 0.9115 - val_loss: 0.2393 - val_acc: 0.9532\n",
      "Epoch 3/10\n",
      "2367/2367 [==============================] - 13s 6ms/step - loss: 0.1916 - acc: 0.9567 - val_loss: 0.2067 - val_acc: 0.9532\n",
      "Epoch 4/10\n",
      "2367/2367 [==============================] - 12s 5ms/step - loss: 0.1841 - acc: 0.9567 - val_loss: 0.1707 - val_acc: 0.9532\n",
      "Epoch 5/10\n",
      "2367/2367 [==============================] - 13s 5ms/step - loss: 0.1703 - acc: 0.9567 - val_loss: 0.1796 - val_acc: 0.9532\n",
      "Epoch 6/10\n",
      "2367/2367 [==============================] - 15s 6ms/step - loss: 0.1625 - acc: 0.9567 - val_loss: 0.1673 - val_acc: 0.9532\n",
      "Epoch 7/10\n",
      "2367/2367 [==============================] - 17s 7ms/step - loss: 0.1612 - acc: 0.9567 - val_loss: 0.1621 - val_acc: 0.9532\n",
      "Epoch 8/10\n",
      "2367/2367 [==============================] - 15s 7ms/step - loss: 0.1543 - acc: 0.9567 - val_loss: 0.1585 - val_acc: 0.9532\n",
      "Epoch 9/10\n",
      "2367/2367 [==============================] - 15s 6ms/step - loss: 0.1467 - acc: 0.9567 - val_loss: 0.1436 - val_acc: 0.9532\n",
      "Epoch 10/10\n",
      "2367/2367 [==============================] - 15s 6ms/step - loss: 0.1320 - acc: 0.9569 - val_loss: 0.1180 - val_acc: 0.9635\n"
     ]
    }
   ],
   "source": [
    "# LSTM for sequence classification in the IMDB dataset\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM,Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "embedding_dim = 8\n",
    "\n",
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(tokenizer.word_index)+1, embedding_dim, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(Bidirectional(LSTM(200,return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(200)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=512)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-acc = 91.38149556400506\n",
      "test-acc = 90.63116370808679\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import itertools\n",
    "\n",
    "train_pred = model.predict(x_train)\n",
    "test_pred = model.predict(x_val)\n",
    "print(\"train-acc = \" + str(accuracy_score(np.argmax(y_train, axis=1), np.argmax(train_pred, axis=1))*100))\n",
    "print(\"test-acc = \" + str(accuracy_score(np.argmax(y_val, axis=1), np.argmax(test_pred, axis=1))*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Transform labels to one-hot\n",
    "lb = LabelBinarizer()\n",
    "Y = lb.fit_transform(data.type)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(np.argmax(y_val, axis=1), np.argmax(test_pred, axis=1))\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(lb.classes_))\n",
    "plt.xticks(tick_marks, lb.classes_, rotation=90)\n",
    "plt.yticks(tick_marks, lb.classes_)\n",
    "#for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "#    plt.text(j, i, format(cm[i, j], '.2f'), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > cm.max() / 2. else \"black\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(np.argmax(y_val, axis=1), np.argmax(test_pred, axis=1), target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DNA       0.00      0.00      0.00        22\n",
      "      Hybrid       0.00      0.00      0.00        69\n",
      "     Protein       0.91      1.00      0.95       919\n",
      "         RNA       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      1014\n",
      "   macro avg       0.23      0.25      0.24      1014\n",
      "weighted avg       0.82      0.91      0.86      1014\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faisalg/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Transform labels to one-hot\n",
    "lb = LabelBinarizer()\n",
    "Y = lb.fit_transform(data.type)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(np.argmax(y_val, axis=1), np.argmax(test_pred, axis=1))\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(lb.classes_))\n",
    "plt.xticks(tick_marks, lb.classes_, rotation=90)\n",
    "plt.yticks(tick_marks, lb.classes_)\n",
    "#for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "#    plt.text(j, i, format(cm[i, j], '.2f'), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > cm.max() / 2. else \"black\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(np.argmax(y_val, axis=1), np.argmax(test_pred, axis=1), target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(len(tokenizer.word_index)+1, embedding_dim, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(GRU(100,return_sequences=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
